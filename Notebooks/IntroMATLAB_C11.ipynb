{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a la Programación en MATLAB (C11)\n",
    "\n",
    "Mauricio Tejada\n",
    "\n",
    "ILADES - Universidad Alberto Hurtado\n",
    "\n",
    "Agosto 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenidos\n",
    "\n",
    "- [Optimización](#11.-Optimización)\n",
    "    - [Métodos Numéricos de Optimización: Ideas Básicas](#11.1-Métodos-Numéricos-de-Optimización:-Ideas-Básicas)\n",
    "    - [El Toolbox de Optimización de Matlab](#12.2-El-Toolbox-de-Optimización-de-Matlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Optimización\n",
    "\n",
    "*La exposición en esta sección sigue de cerca el capítulo 4 del libro de Miranda y Fackler.*\n",
    "\n",
    "En esta sección se describe cómo maximizar numéricamente una función respecto de un vector finito de variables. El problema a resolver es entonces:\n",
    "\n",
    "$$\\max_{x \\in X} f(x)$$\n",
    "\n",
    "con $x \\subseteq R^n$. En este problemas denominamos a $f$ como la función objetivos, a $X$ como el conjunto factible y a $x^*$ como el máximo (si existe).\n",
    "\n",
    "Los problemas de optimización finitos son muy comunes en economía.\n",
    "\n",
    "*Teorema de Wierstrass**\n",
    "\n",
    "Si $f$ es continua y $X$ es un conjunto no vacío, cerrado y acotado, entonces $f$ tiene un máximo en $X$. \n",
    "\n",
    "Condición de Primer Orden:\n",
    "\n",
    "$$f'(x^*) = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Métodos Numéricos de Optimización: Ideas Básicas\n",
    "\n",
    "#### El Método de Newton-Rapson\n",
    "\n",
    "El método de Newton-Rapson usa una sucesión de aproximaciones cuadráticas de la función objetivo y el máximo de la aproximación debería converger al máximo de la función. \n",
    "\n",
    "Este método está estrechamente relacionado con el método de Newton para buscar las raíces de una función.\n",
    "\n",
    "El método es iterativo y se inicia con una conjetura $x^{(0)}$ de la solución. \n",
    "\n",
    "A continuación se actualiza la solución de $x^{(k)}$ a $x^{(k+1)}$ minimizando:\n",
    "\n",
    "$$f(x) \\approx f(x^{(k)}) + f'(x^{(k)})(x-x^{(k)}) + 0.5 (x-x^{(k)})^{T}f''(x^{(k)})(x-x^{(k)})$$\n",
    "\n",
    "respecto de $x$. La condición de primero orden es:\n",
    "\n",
    "$$f'(x^{(k)}) + f''(x^{(k)})(x-x^{(k)})=0$$\n",
    "\n",
    "y por tanto:\n",
    "\n",
    "$$x^{(k+1)} \\leftarrow x^{(k)} - [f''(x^{(k)})]^{-1} f'(x^{(k)})$$\n",
    "\n",
    "El algoritmo termina cuando $x^{(k+1)}$ es suficientemente cercano a $x^{(k)}$. \n",
    "\n",
    "\n",
    "Limitaciones:\n",
    "- Se requiere computar tanto la primera como la segunda derivadas de la función (el gradiente y la matriz hessiana).\n",
    "- No hay garantía que la función se incremente en la dirección de la actualización (esto se garantiza sólo si $f''$ es definida negativa).\n",
    "- EL método de Newton-Rapson es usada sólo cuando la función es globalmente cóncava.\n",
    "\n",
    "#### El Método de Quasi-Newton\n",
    "\n",
    "Sigue la misma idea que el método de Newton-Rapson pero reemplaza la matriz hessiana con una aproximación que es definida negativa (garantizando incrementos en la función).\n",
    "\n",
    "Por eficiencia, la aproximación se realiza directamente sobre la inversa de la matriz hessiana.\n",
    "\n",
    "Dos métodos satisfacen está idea:\n",
    "- Davidson-Fletcher-Powell (DFP)\n",
    "- Broyden-Fletcher-Goldfarb-Shano (BFGS)\n",
    "\n",
    "La diferencia entre ambos radica en cómo actualizan la aproximación de la inversa de la matriz hessiana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 El Toolbox de Optimización de Matlab\n",
    "\n",
    "El toolbox de optimización de Matlab contiene funciones que permiten minimizar (o maximizar) funciones no lineales generales.\n",
    "\n",
    "El toolbox incluye rutinas para realizar muchos tipos de procedimientos de optimización. Los que usaremos son:\n",
    "- Minimización no lineal no restringida `fminunc` \n",
    "- Minimización no lineal restringida `fmincon`\n",
    "\n",
    "Las funciones `fzero` y `fsolve` ya vistas son también parte de este toolbox.\n",
    "\n",
    "**Nota:** Matlab tiene implementados los métodos numéricos anteriores pero con el objetivo de minimizar una función. La maximización se realiza simplemente minimizando el negativo de la función objetivos.\n",
    "\n",
    "#### Minimización No Restringida\n",
    "\n",
    "Matlab minimiza (o maximiza) funciones no lineales sin restricciones usando la función `fminunc`. \n",
    "\n",
    "La función busca iterativamente el mínimo de una función escalar con varias variables a partir de una conjetura inicial. \n",
    "\n",
    "Esta función usa los métodos de Quasi-Newton si el gradiente no es provisto por el usuario.\n",
    "\n",
    "La sintaxis general es:\n",
    "\n",
    "`[x,fval,exitflag,output,grad,hess] = fminunc('fun',x0,... opts)`\n",
    "\n",
    "Los inputs de la función son:\n",
    "\n",
    "- `'fun'`: Función escalar objetivo. Puede estar escrita en un m-file o ser una función anónima.\n",
    "- `x0`: Conjetura inicial.\n",
    "- `opts`: estructura con las opciones de optimización (número de iteraciones, tolerancia, algoritmo, entre otros).\n",
    "\n",
    "Los outputs de la función son:\n",
    "\n",
    "- `x`: Solución ($x^*$).\n",
    "- `fval`: Valor de la función objetivo en el mínimo.\n",
    "- `exitflag`: Condición de salida de la función `fminunc`. La solución fue hallada si `existflag>0`.\n",
    "- `output`: Estructura con información de la optimización (número de iteración, número de evaluaciones de la función, condición de primer orden, etc).\n",
    "- `grad`: Gradiente evaluado en la solución.\n",
    "- `hess`: Matriz hessiana evaluada en la solución.\n",
    "\n",
    "Resolvamos el siguiente ejemplo:\n",
    "\n",
    "$$f(x)=3x^2_1 +2x_1 x_2 +x^2_2 -4x_1 + 5x_2$$\n",
    "\n",
    "Escribamos la función anónima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fun =\n",
      "\n",
      "  function_handle with value:\n",
      "\n",
      "    @(x)3*x(1)^2+2*x(1)*x(2)+x(2)^2-4*x(1)+5*x(2)\n"
     ]
    }
   ],
   "source": [
    "clear all;\n",
    "fun = @(x) 3*x(1)^2 + 2*x(1)*x(2) + x(2)^2 - 4*x(1) + 5*x(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usamos la función `fminunc` para hallar el mínimo partiendo de la conjetura $[1,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local minimum found.\n",
      "\n",
      "Optimization completed because the size of the gradient is less than\n",
      "the default value of the optimality tolerance.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x =\n",
      "\n",
      "    2.2500   -4.7500\n",
      "\n",
      "\n",
      "fval =\n",
      "\n",
      "  -16.3750\n",
      "\n",
      "\n",
      "eflag =\n",
      "\n",
      "     1\n",
      "\n",
      "\n",
      "out = \n",
      "\n",
      "  struct with fields:\n",
      "\n",
      "       iterations: 8\n",
      "        funcCount: 27\n",
      "         stepsize: 7.3113e-05\n",
      "     lssteplength: 1\n",
      "    firstorderopt: 3.8147e-06\n",
      "        algorithm: 'quasi-newton'\n",
      "          message: 'Local minimum found....'\n"
     ]
    }
   ],
   "source": [
    "warning('off');\n",
    "x0 = [1,1];\n",
    "[x,fval, eflag, out] = fminunc(@(x) fun(x),x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      "\n",
      "    2.2500   -4.7500\n",
      "\n",
      "\n",
      "fval =\n",
      "\n",
      "  -16.3750\n",
      "\n",
      "\n",
      "eflag =\n",
      "\n",
      "     1\n"
     ]
    }
   ],
   "source": [
    "x0 = [1,1];\n",
    "[x,fval, eflag] = fminsearch(@(x) fun(x),x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimización Restringida\n",
    "\n",
    "Ahora el objetivo es encontrar $x$ que minimiza la función no lineal objetivo $f(x)$ sujeto a restricciones, que pueden ser lineales o no lineales y pueden de igualdad o de desigualdad.\n",
    "\n",
    "El problema general es:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\min_{x} && f(x) \\\\\n",
    "s.a & & \\\\\n",
    "&& Ax = b \\\\\n",
    "&& C(x) = 0  \\\\\n",
    "&& AIx \\leq bI \\\\\n",
    "&& CI(x) = 0 \\\\\n",
    "&& lb \\leq x \\leq ub \n",
    "\\end{eqnarray}\n",
    "\n",
    "donde $A$ y $AI$ son matrices, $C(x)$ y $CI(x)$ son funciones no lineales, $b$ y $bI$ son vectores columna. La dimensiones de estos objetos dependen del número de restricciones. Finalmente, $lb$ y $ub$ son vectores columnas de la misma dimensión que $x$.\n",
    "\n",
    "La función para resolver problemas de optimización con restricciones en Matlab es `fmincon`. Funciones de la misma forma que `fminunc` pero tiene una mayor cantidad de inputs.\n",
    "\n",
    "Las sintaxis general es:\n",
    "\n",
    "`[x,fval,existflag,output,lambda,grad,hess] = fmincon('fun',x0,AI,bI,A,b,lb,ub,'NonConFunc',Options)`\n",
    "\n",
    "- `'fun'`: Función escalar objetivo. Puede estar escrita en un m-file o ser una función anónima.\n",
    "- `x0`: Conjetura inicial.\n",
    "- `AI` y `bI` caracterizan las restricciones de desigualdad (si no existen éstas usar `AI=[]` y `bI=[]`).\n",
    "- `A` y `b` caracterizan las restricciones de igualdad (si no existen éstas usar `A=[]` y `b=[]`).\n",
    "- `lb` y `ub` caracterizan las cotas inferiores y superiores de $x$ (si no existen éstas usar `lb=[]` y `ub=[]`).\n",
    "- `'NonConFunc'`: es una función que tiene `x` como input y retorna vectores `CI(x)` y `C(x)` asociados a las restricciones de desigualdad e igualdad no lineales.\n",
    "- `opts`: estructura con las opciones de optimización (número de iteraciones, tolerancia, algoritmo, entre otros).\n",
    "\n",
    "Los outputs de la función son:\n",
    "\n",
    "- `x`: Solución ($x^*$).\n",
    "- `fval`: Valor de la función objetivo en el mínimo.\n",
    "- `exitflag`: Condición de salida de la función `fminunc`. La solución fue hallada si `existflag>0`.\n",
    "- `output`: Estructura con información de la optimización (número de iteración, número de evaluaciones de la función, condición de primer orden, etc).\n",
    "- `lambda`: Estructura con los multiplicadores de lagrange asociados a las restricciones.\n",
    "- `grad`: Gradiente evaluado en la solución.\n",
    "- `hess`: Matriz hessiana evaluada en la solución.\n",
    "\n",
    "A modo de ejemplo, resolvamos el siguiente problema:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\min_{x_1,x_2} && f(x_1,x_2) = 100(x_2-x^2_1)^2 + (1-x_1)^2 \\\\\n",
    "s.a & & \\\\\n",
    "&& x_1 + 2x_2 \\leq 1\\\\\n",
    "&& 2x_1 + x_2= 1  \n",
    "\\end{eqnarray}\n",
    "\n",
    "Definimos la función objetivo:\n",
    "\n",
    "```\n",
    "function f = rosenbrock(x)\n",
    "\n",
    "x1 = x(1);\n",
    "x2 = x(2);\n",
    "\n",
    "f = 100*(x2-x1^2)^2 + (1-x1)^2;\n",
    "\n",
    "end\n",
    "```\n",
    "\n",
    "Definimos las restricciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clear all;\n",
    "x0 = [0.5,0];\n",
    "A = [1,2];\n",
    "b = 1;\n",
    "Aeq = [2,1];\n",
    "beq = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local minimum found that satisfies the constraints.\n",
      "\n",
      "Optimization completed because the objective function is non-decreasing in \n",
      "feasible directions, to within the default value of the optimality tolerance,\n",
      "and constraints are satisfied to within the default value of the constraint tolerance.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x =\n",
      "\n",
      "    0.4149    0.1701\n",
      "\n",
      "\n",
      "fval =\n",
      "\n",
      "    0.3427\n"
     ]
    }
   ],
   "source": [
    "[x, fval] = fmincon(@rosenbrock,x0,A,b,Aeq,beq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora resolvamos el siguiente problema:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\min_{x_1,x_2} && f(x_1,x_2) = 1+\\frac{x_1}{(1+x_2)} - 3x_1x_2 + x_2(1+x_1) \\\\\n",
    "s.a & & \\\\\n",
    "&&  0 \\leq x_1 \\leq 1\\\\\n",
    "&&  0 \\leq x_2 \\leq 2\\\\\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FunObj = @(x) 1+x(1)/(1+x(2)) - 3*x(1)*x(2) + x(2)*(1+x(1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restricciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lb = [0,0];\n",
    "ub = [10,10];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local minimum found that satisfies the constraints.\n",
      "\n",
      "Optimization completed because the objective function is non-decreasing in \n",
      "feasible directions, to within the default value of the optimality tolerance,\n",
      "and constraints are satisfied to within the default value of the constraint tolerance.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x =\n",
      "\n",
      "   10.0000   10.0000\n"
     ]
    }
   ],
   "source": [
    "x0 = [0.5,1];\n",
    "x = fmincon(FunObj,x0,[],[],[],[],lb,ub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
